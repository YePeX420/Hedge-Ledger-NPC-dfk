BACKEND PROMPT 2 — Combat Codex Ingestion + Auto-Discovery + Sync Status Tracking

Objective

Implement the Combat Codex ingestion engine in the backend project that:

1. Auto-discovers new combat class pages from the official combat index


2. Ingests Combat Keywords + Class Skills tables into Neon


3. Tracks full sync status in DB (runs + per-item results) so Admin UI can show health/history


4. Adds a nightly scheduler (03:00 America/Puerto_Rico) to refresh automatically



Do not build the Admin UI pages yet. This prompt only adds ingestion + DB sync status + basic internal code wiring.


---

A) Add DB migrations for sync status

Create a new migration that adds:

sync_runs

Tracks each ingest run summary.

create table if not exists sync_runs (
  id bigserial primary key,
  domain text not null, -- e.g. 'combat_codex'
  started_at timestamptz not null default now(),
  finished_at timestamptz,
  status text not null check (status in ('running','success','failed')),
  discovered_urls int not null default 0,
  keywords_upserted int not null default 0,
  classes_attempted int not null default 0,
  classes_ingested int not null default 0,
  skills_upserted int not null default 0,
  rag_docs_upserted int not null default 0,
  error text,
  log jsonb
);

create index if not exists ix_sync_runs_domain_started
  on sync_runs(domain, started_at desc);

sync_run_items

Tracks per-class results (success/skipped/failed).

create table if not exists sync_run_items (
  id bigserial primary key,
  sync_run_id bigint not null references sync_runs(id) on delete cascade,
  item_type text not null, -- 'class_url' | 'keywords'
  item_key text not null,  -- url or identifier
  status text not null check (status in ('success','skipped','failed')),
  detail text,
  skills_count int,
  updated_at timestamptz not null default now()
);

create index if not exists ix_sync_run_items_run
  on sync_run_items(sync_run_id);


---

B) Install required dependencies

Add these packages (if missing):

npm i cheerio p-limit node-cron

(You already have pg from Prompt 1’s DB wiring.)


---

C) Create ingestion module (full file)

Create: src/dfk/combatCodexIngestor.ts

This module must:

Discover class URLs from https://docs.defikingdoms.com/gameplay/combat

Upsert discovery into combat_sources

Ingest combat keywords into combat_keywords

Ingest class meta + skills into combat_class_meta + combat_skills

Track run status in sync_runs + sync_run_items

Be robust to GitBook HTML changes (header-based table matching)

Skip pages with no skills table (record as skipped) rather than failing whole run


Implement it exactly as follows:

import * as cheerio from "cheerio";
import pLimit from "p-limit";
import { withClient } from "../db";

type RunStatus = "running" | "success" | "failed";
type ItemStatus = "success" | "skipped" | "failed";

const COMBAT_OVERVIEW_URL = "https://docs.defikingdoms.com/gameplay/combat";
const UA = process.env.HEDGE_BOT_UA || "HedgeLedgerBot/1.0 (combat-codex-ingestor)";

function norm(s: string) {
  return (s || "").replace(/\s+/g, " ").trim();
}

async function fetchHtml(url: string): Promise<string> {
  const res = await fetch(url, {
    headers: {
      "User-Agent": UA,
      "Accept": "text/html,application/xhtml+xml",
    },
  });
  if (!res.ok) throw new Error(`Fetch failed ${res.status} for ${url}`);
  return await res.text();
}

function findTableByHeaders($: cheerio.CheerioAPI, required: string[]) {
  const tables = $("table");
  for (let i = 0; i < tables.length; i++) {
    const t = tables.eq(i);
    const headers = t.find("thead tr th").toArray().map(th => norm($(th).text()).toLowerCase());
    const ok = required.every(h => headers.includes(h.toLowerCase()));
    if (ok) return t;
  }
  return null;
}

function extractLastUpdateNote($: cheerio.CheerioAPI) {
  const text = norm($("body").text());
  const idx = text.toLowerCase().indexOf("last update");
  if (idx === -1) return null;
  return text.slice(Math.max(0, idx - 40), Math.min(text.length, idx + 220));
}

function classifyMaturity($: cheerio.CheerioAPI) {
  const t = $("body").text().toLowerCase();
  if (t.includes("pre-alpha")) return "pre_alpha";
  if (t.includes("beyond tier 5") && t.includes("not yet been revised")) return "revised_through_tier_5";
  return "unknown";
}

function parseNumberLoose(s: string) {
  const c = (s || "").replace(/[,]/g, "").trim();
  if (!c) return null;
  const n = Number(c);
  return Number.isFinite(n) ? n : null;
}

function parseKeywordTable($: cheerio.CheerioAPI, table: cheerio.Cheerio<any>) {
  const out: { keyword: string; definition: string }[] = [];
  table.find("tbody tr").each((_, tr) => {
    const cells = $(tr).find("td").toArray().map(td => norm($(td).text()));
    if (cells.length < 2) return;
    const keyword = cells[0];
    const definition = cells.slice(1).join(" | ");
    if (!keyword || !definition) return;
    out.push({ keyword, definition });
  });
  return out;
}

function parseCombatKeywords(html: string) {
  const $ = cheerio.load(html);
  const table =
    findTableByHeaders($, ["Keyword", "Definition"]) ||
    $("table").filter((_, el) => {
      const headers = $(el).find("thead tr th").toArray().map(th => norm($(th).text()).toLowerCase());
      return headers.some(h => h.includes("keyword")) && headers.some(h => h.includes("definition"));
    }).first();

  if (!table || table.length === 0) return [];
  return parseKeywordTable($, table);
}

function parseClassNameFromUrl(url: string) {
  const last = url.split("/").filter(Boolean).pop() || url;
  return last.charAt(0).toUpperCase() + last.slice(1);
}

function discoverClassUrlsFromCombatIndex(html: string) {
  const $ = cheerio.load(html);
  const urls = new Set<string>();

  $("a[href]").each((_, a) => {
    const href = (($(a).attr("href") || "").trim());
    if (!href) return;

    let u: URL;
    try {
      u = href.startsWith("http") ? new URL(href) : new URL(href, COMBAT_OVERVIEW_URL);
    } catch {
      return;
    }

    if (u.hostname !== "docs.defikingdoms.com") return;

    const path = u.pathname.replace(/\/+$/, "");
    if (!path.startsWith("/gameplay/combat/")) return;
    if (path === "/gameplay/combat") return;

    urls.add(`https://docs.defikingdoms.com${path}`);
  });

  return [...urls].sort();
}

function parseSkillsTable($: cheerio.CheerioAPI, table: cheerio.Cheerio<any>) {
  const headers = table.find("thead tr th").toArray().map(th => norm($(th).text()));
  const idx = new Map<string, number>();
  headers.forEach((h, i) => idx.set(h.toLowerCase(), i));

  const findIdx = (cands: string[]) => {
    for (const c of cands) {
      const k = c.toLowerCase();
      if (idx.has(k)) return idx.get(k)!;
    }
    for (const [k, v] of idx.entries()) {
      for (const c of cands) if (k.includes(c.toLowerCase())) return v;
    }
    return null;
  };

  const iSkillPoints = findIdx(["skill points", "points"]);
  const iDiscipline  = findIdx(["discipline"]);
  const iAbility     = findIdx(["ability", "skill"]);
  const iDesc        = findIdx(["description", "effect"]);
  const iRange       = findIdx(["range"]);
  const iMana        = findIdx(["mana cost/growth", "mana cost / growth", "mana cost", "mana"]);
  const iDod         = findIdx(["dod", "degree of difficulty"]);

  const rows: any[] = [];

  table.find("tbody tr").each((_, tr) => {
    const cells = $(tr).find("td").toArray().map(td => norm($(td).text()));
    if (!cells.length) return;

    const ability = (iAbility !== null ? cells[iAbility] : "") || "";
    if (!ability) return;

    const discipline = iDiscipline !== null ? cells[iDiscipline] : null;
    const description_raw = iDesc !== null ? cells[iDesc] : null;
    const skill_points = iSkillPoints !== null ? parseNumberLoose(cells[iSkillPoints]) : null;
    const range = iRange !== null ? parseNumberLoose(cells[iRange]) : null;
    const dod = iDod !== null ? parseNumberLoose(cells[iDod]) : null;

    let mana_cost: number | null = null;
    let mana_growth: number | null = null;
    if (iMana !== null && cells[iMana]) {
      const parts = cells[iMana].split("/").map(p => p.trim());
      mana_cost = parts[0] ? parseNumberLoose(parts[0]) : null;
      mana_growth = parts[1] ? parseNumberLoose(parts[1]) : null;
    }

    rows.push({
      skill_points,
      discipline,
      ability,
      description_raw,
      range,
      mana_cost,
      mana_growth,
      dod,
    });
  });

  return rows;
}

function tryFindSkillsTable($: cheerio.CheerioAPI) {
  return (
    findTableByHeaders($, ["Skill Points", "Discipline", "Ability", "Description"]) ||
    findTableByHeaders($, ["Skill Points", "Discipline", "Ability", "Description", "Range"]) ||
    null
  );
}

export async function ingestCombatCodex(opts?: { discover?: boolean; concurrency?: number }) {
  const discover = opts?.discover ?? true;
  const concurrency = opts?.concurrency ?? 3;

  // Create sync run
  const runId = await withClient(async (client) => {
    const r = await client.query(
      `insert into sync_runs(domain, status) values ('combat_codex','running') returning id`
    );
    return r.rows[0].id as number;
  });

  const updateRun = async (patch: Partial<{
    status: RunStatus;
    discovered_urls: number;
    keywords_upserted: number;
    classes_attempted: number;
    classes_ingested: number;
    skills_upserted: number;
    rag_docs_upserted: number;
    error: string | null;
    log: any;
  }>) => {
    await withClient(async (client) => {
      const fields: string[] = [];
      const vals: any[] = [];
      let i = 1;

      for (const [k, v] of Object.entries(patch)) {
        fields.push(`${k} = $${i++}`);
        vals.push(v);
      }
      fields.push(`updated_at = updated_at`); // no-op for compatibility if you add column later
      vals.push(runId);

      await client.query(
        `update sync_runs set ${fields.join(", ")}, finished_at = case when $${i}::text in ('success','failed') then now() else finished_at end
         where id = $${i}`,
        [...vals, patch.status ?? "running"]
      );
    });
  };

  const upsertItem = async (item: { item_type: string; item_key: string; status: ItemStatus; detail?: string | null; skills_count?: number | null }) => {
    await withClient(async (client) => {
      await client.query(
        `
        insert into sync_run_items(sync_run_id, item_type, item_key, status, detail, skills_count, updated_at)
        values ($1,$2,$3,$4,$5,$6,now())
        `,
        [runId, item.item_type, item.item_key, item.status, item.detail ?? null, item.skills_count ?? null]
      );
    });
  };

  try {
    // Fetch combat index
    const combatIndexHtml = await fetchHtml(COMBAT_OVERVIEW_URL);

    // Discovery
    let discoveredUrls: string[] = [];
    if (discover) {
      discoveredUrls = discoverClassUrlsFromCombatIndex(combatIndexHtml);

      await withClient(async (client) => {
        await client.query("begin");
        try {
          // ensure overview present
          await client.query(
            `
            insert into combat_sources(url, kind, enabled, discovered_from, last_seen_at)
            values ($1,'combat_overview',true,'auto_discovery',now())
            on conflict (url) do update set last_seen_at=now()
            `,
            [COMBAT_OVERVIEW_URL]
          );

          for (const url of discoveredUrls) {
            await client.query(
              `
              insert into combat_sources(url, kind, enabled, discovered_from, last_seen_at)
              values ($1,'combat_class',true,$2,now())
              on conflict (url) do update set last_seen_at=now(), discovered_from=excluded.discovered_from
              `,
              [url, COMBAT_OVERVIEW_URL]
            );
          }
          await client.query("commit");
        } catch (e) {
          await client.query("rollback");
          throw e;
        }
      });

      await updateRun({ discovered_urls: discoveredUrls.length });
    }

    // Keywords
    const keywords = parseCombatKeywords(combatIndexHtml);
    await withClient(async (client) => {
      await client.query("begin");
      try {
        for (const k of keywords) {
          await client.query(
            `
            insert into combat_keywords(keyword, definition, source_url, last_seen_at)
            values ($1,$2,$3,now())
            on conflict (keyword) do update set definition=excluded.definition, source_url=excluded.source_url, last_seen_at=now()
            `,
            [k.keyword, k.definition, COMBAT_OVERVIEW_URL]
          );
        }
        await client.query("commit");
      } catch (e) {
        await client.query("rollback");
        throw e;
      }
    });
    await upsertItem({ item_type: "keywords", item_key: COMBAT_OVERVIEW_URL, status: "success", detail: `Upserted ${keywords.length} keywords` });
    await updateRun({ keywords_upserted: keywords.length });

    // Get enabled sources from DB
    const classUrls = await withClient(async (client) => {
      const q = await client.query(
        `select url from combat_sources where kind='combat_class' and enabled=true order by url asc`
      );
      return q.rows.map(r => r.url as string);
    });

    await updateRun({ classes_attempted: classUrls.length });

    const limit = pLimit(concurrency);
    let classesIngested = 0;
    let skillsUpserted = 0;

    await Promise.all(
      classUrls.map((url) =>
        limit(async () => {
          try {
            const html = await fetchHtml(url);
            const $ = cheerio.load(html);

            const className = parseClassNameFromUrl(url);
            const maturity = classifyMaturity($);
            const lastUpdateNote = extractLastUpdateNote($);
            const summary = norm(($("main").text() || $("body").text()).slice(0, 320));

            const table = tryFindSkillsTable($);
            if (!table) {
              await upsertItem({ item_type: "class_url", item_key: url, status: "skipped", detail: "No skills table found", skills_count: 0 });
              return;
            }

            const skillRows = parseSkillsTable($, table);
            if (!skillRows.length) {
              await upsertItem({ item_type: "class_url", item_key: url, status: "skipped", detail: "Skills table empty", skills_count: 0 });
              return;
            }

            // Upsert class meta + skills
            await withClient(async (client) => {
              await client.query("begin");
              try {
                await client.query(
                  `
                  insert into combat_class_meta(class, source_url, last_update_note, maturity, disciplines, summary, last_seen_at)
                  values ($1,$2,$3,$4,$5,$6,now())
                  on conflict (class) do update set
                    source_url=excluded.source_url,
                    last_update_note=excluded.last_update_note,
                    maturity=excluded.maturity,
                    disciplines=excluded.disciplines,
                    summary=excluded.summary,
                    last_seen_at=now()
                  `,
                  [className, url, lastUpdateNote, maturity, [], summary]
                );

                let localUpserts = 0;
                for (const s of skillRows) {
                  // tier detection is not reliable yet; store tier=0 for now (we’ll improve later)
                  const tier = 0;

                  await client.query(
                    `
                    insert into combat_skills(
                      class, tier, skill_points, discipline, ability, description_raw, range,
                      mana_cost, mana_growth, dod, tags, source_url, last_seen_at
                    ) values (
                      $1,$2,$3,$4,$5,$6,$7,
                      $8,$9,$10,$11,$12,now()
                    )
                    on conflict (class, tier, coalesce(discipline,''), ability, coalesce(skill_points,-1))
                    do update set
                      description_raw=excluded.description_raw,
                      range=excluded.range,
                      mana_cost=excluded.mana_cost,
                      mana_growth=excluded.mana_growth,
                      dod=excluded.dod,
                      tags=excluded.tags,
                      source_url=excluded.source_url,
                      last_seen_at=now()
                    `,
                    [
                      className,
                      tier,
                      s.skill_points,
                      s.discipline,
                      s.ability,
                      s.description_raw,
                      s.range,
                      s.mana_cost,
                      s.mana_growth,
                      s.dod,
                      [],
                      url,
                    ]
                  );
                  localUpserts++;
                }

                await client.query("commit");

                classesIngested++;
                skillsUpserted += localUpserts;

                await upsertItem({ item_type: "class_url", item_key: url, status: "success", detail: `Upserted ${localUpserts} skills`, skills_count: localUpserts });
              } catch (e) {
                await client.query("rollback");
                throw e;
              }
            });
          } catch (e: any) {
            await upsertItem({ item_type: "class_url", item_key: url, status: "failed", detail: e?.message ?? String(e) });
          }
        })
      )
    );

    await updateRun({
      classes_ingested: classesIngested,
      skills_upserted: skillsUpserted,
      status: "success",
      log: { note: "Combat codex ingest completed" },
    });

    return { ok: true, runId, discoveredUrls: discoveredUrls.length, keywords: keywords.length, classesAttempted: classUrls.length, classesIngested, skillsUpserted };
  } catch (e: any) {
    await updateRun({ status: "failed", error: e?.message ?? String(e) });
    throw e;
  }
}

Notes:

Tier parsing is set to tier=0 for now. That is acceptable for this prompt; we will improve tier inference later if needed.

Tags and disciplines arrays are empty for now; we will enrich them later. This prompt is about working ingestion + sync.



---

D) Add nightly scheduler

Create: src/jobs/combatCodexCron.ts

import cron from "node-cron";
import { ingestCombatCodex } from "../dfk/combatCodexIngestor";

export function startCombatCodexCron() {
  cron.schedule(
    "0 3 * * *",
    async () => {
      try {
        console.log("[combat-codex] nightly ingest start");
        const r = await ingestCombatCodex({ discover: true, concurrency: 3 });
        console.log("[combat-codex] nightly ingest done", r);
      } catch (e: any) {
        console.error("[combat-codex] nightly ingest failed", e?.message ?? e);
      }
    },
    { timezone: "America/Puerto_Rico" }
  );
}

Then in your server entrypoint (src/server.ts), import and call:

import { startCombatCodexCron } from "./jobs/combatCodexCron";
startCombatCodexCron();


---

E) Quick internal test route (temporary)

Add a temporary admin-only route to trigger ingest (we will replace with proper admin APIs in Prompt 3):

Create stub router file if needed: src/routes/admin/combatIngestTest.ts

import { Router } from "express";
import { ingestCombatCodex } from "../../dfk/combatCodexIngestor";

export const adminCombatIngestTestRouter = Router();

adminCombatIngestTestRouter.post("/combat/ingest-test", async (_req, res) => {
  try {
    const r = await ingestCombatCodex({ discover: true, concurrency: 3 });
    res.json(r);
  } catch (e: any) {
    res.status(500).json({ ok: false, error: e?.message ?? String(e) });
  }
});

Mount under /api/admin (admin-key protected), e.g.:

app.use("/api/admin", adminCombatIngestTestRouter);


---

Acceptance Criteria

1. POST /api/admin/combat/ingest-test triggers a sync run.


2. Neon tables populate:

combat_sources contains discovered class URLs

combat_keywords has entries

combat_class_meta and combat_skills have rows (at least some classes)



3. sync_runs has a row with status=success or failed


4. sync_run_items contains per-class outcomes including skipped pages


5. Nightly cron is scheduled (log on startup or verify schedule is registered)




---

When done, tell me “Next” and I will provide Backend Prompt 3 (Admin Combat API: refresh/status/sources/sync history) as a single pasteable prompt.